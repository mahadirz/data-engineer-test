{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Test (Part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing all required libraries ahead of time :)\n",
    "#easy to spot any libraries not currently not installed in ur machine\n",
    "%run kaggle.py\n",
    "import json\n",
    "from pyspark.sql import SparkSession,Row\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer,StopWordsRemover, CountVectorizer,VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "String similarity (code in python):<br>\n",
    "a) Download test.csv from https://www.kaggle.com/rishisankineni/text-similarity/data<br>\n",
    "b) Load the data to a Spark/Pandas data frame<br>\n",
    "c) Calculate similarity between description_x and description_y and store resultant<br>\n",
    "scores in a new column<br>\n",
    "d) Parallelise the matching process (bonus)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Kaggle credentials\n",
    "# $ cp cred.json.example cred.json\n",
    "# $ vim cred.json \n",
    "cred = json.load(open('cred.json'))\n",
    "\n",
    "#login first and create browser instance\n",
    "kaggle = Kaggle()\n",
    "kaggle.login(cred['UserName'],cred['Password'])\n",
    "local_file = \"q4_test.csv\"\n",
    "dataset_url = \"https://www.kaggle.com/rishisankineni/text-similarity/downloads/test.csv\"\n",
    "kaggle.download_dataset(dataset_url,local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q4_df = spark.read.csv(\"q4_test.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------------+\n",
      "|test_id|       description_x|       description_y|same_security|\n",
      "+-------+--------------------+--------------------+-------------+\n",
      "|      0|        semtech corp| semtech corporation|         null|\n",
      "|      1|vanguard mid cap ...|vanguard midcap i...|         null|\n",
      "|      2|spdr gold trust g...|spdr gold trust s...|         null|\n",
      "|      3|vanguard total bo...|vanguard total bo...|         null|\n",
      "|      4|oakmark internati...|oakmark internati...|         null|\n",
      "|      5|pfizer inc div: 1...|      pfizer inc com|         null|\n",
      "|      6|spartan global ex...|sptn glb xus idx adv|         null|\n",
      "|      7|vanguard total bo...|vanguard total bo...|         null|\n",
      "|      8|banco latinoameri...|banco latinoameri...|         null|\n",
      "|      9|baidu inc fadr 1 ...|baidu inc spons a...|         null|\n",
      "|     10|  whole foods market|whole foods marke...|         null|\n",
      "|     11|walgreens boots a...|walgreens boots alli|         null|\n",
      "|     12|diageo plc new gb...|diageo p l c spon...|         null|\n",
      "|     13|guggenheim bullet...|guggenheim bullet...|         null|\n",
      "|     14|vanguard small-ca...|vanguard small-ca...|         null|\n",
      "|     15|    emerging markets|vanguard ftse eme...|         null|\n",
      "|     16| spdr s&p 500 etf iv|  s&p 500 index spdr|         null|\n",
      "|     17|       tegna inc com|           tegna inc|         null|\n",
      "|     18|     deere & company|            deere co|         null|\n",
      "|     19|vanguard mid-cap ...|vanguard mid-cap ...|         null|\n",
      "+-------+--------------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q4_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"description_x\", outputCol=\"x_token\")\n",
    "stopremove = StopWordsRemover(inputCol='x_token',outputCol='x_stop_tokens')\n",
    "#count_vec = CountVectorizer(inputCol='x_stop_tokens',outputCol='x_vec')\n",
    "hash_tf = HashingTF(inputCol='x_stop_tokens',outputCol='x_vec',numFeatures=20)\n",
    "idf = IDF(inputCol=\"x_vec\", outputCol=\"x_tf_idf\")\n",
    "#clean_up = VectorAssembler(inputCols=['test_id','x_tf_idf'],outputCol='features')\n",
    "\n",
    "data_prep_pipe = Pipeline(stages=[tokenizer,stopremove,hash_tf,idf])\n",
    "pipe = data_prep_pipe.fit(q4_df)\n",
    "_ = pipe.transform(q4_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"description_y\", outputCol=\"y_token\")\n",
    "stopremove = StopWordsRemover(inputCol='y_token',outputCol='y_stop_tokens')\n",
    "hash_tf = HashingTF(inputCol='y_stop_tokens',outputCol='y_vec',numFeatures=20)\n",
    "idf = IDF(inputCol=\"y_vec\", outputCol=\"y_tf_idf\")\n",
    "#clean_up = VectorAssembler(inputCols=['test_id','y_tf_idf'],outputCol='features')\n",
    "\n",
    "data_prep_pipe = Pipeline(stages=[tokenizer,stopremove,hash_tf,idf])\n",
    "pipe = data_prep_pipe.fit(_)\n",
    "_ = pipe.transform(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(test_id=0, x_tf_idf=SparseVector(20, {7: 1.0223, 13: 1.5031}), y_tf_idf=SparseVector(20, {5: 1.7821, 13: 1.5031}))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = _.select(['test_id','x_tf_idf','y_tf_idf'])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|           distance|test_id|\n",
      "+-------------------+-------+\n",
      "|0.46688613087875275|      0|\n",
      "| 0.5382639097773301|      1|\n",
      "|  0.030247583431531|      2|\n",
      "| 0.2503203464381226|      3|\n",
      "| 0.6191473640349485|      4|\n",
      "|0.27824635258317754|      5|\n",
      "|0.47763156314799937|      6|\n",
      "|0.31785068032330166|      7|\n",
      "| 0.1576517596167727|      8|\n",
      "| 0.5400476750834667|      9|\n",
      "| 0.4467747348264962|     10|\n",
      "|0.36047764793855985|     11|\n",
      "|0.15010684463071922|     12|\n",
      "|0.14710627737376425|     13|\n",
      "|  0.374305168167954|     14|\n",
      "| 0.5894585797698484|     15|\n",
      "|0.17665286616467601|     16|\n",
      "| 0.2369017380111672|     17|\n",
      "| 0.4979437935526283|     18|\n",
      "| 0.5078347878293663|     19|\n",
      "+-------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The map operation should be able to distribute to other clusters (if got any)\n",
    "# cosine similarity\n",
    "#1 - x['x_tf_idf'].dot(x['y_tf_idf'])/(x['x_tf_idf'].norm(2)*x['y_tf_idf'].norm(2))\n",
    "#x['x_tf_idf'].squared_distance(x['y_tf_idf'])\n",
    "# choose the built in squared distance\n",
    "new_df = df.select(['test_id','x_tf_idf','y_tf_idf']).rdd.map(\n",
    "    lambda x : Row( distance=float(1 - x['x_tf_idf'].dot(x['y_tf_idf'])/(x['x_tf_idf'].norm(2)*x['y_tf_idf'].norm(2))), test_id=x['test_id'])\n",
    ").toDF()\n",
    "\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|          distance|test_id|\n",
      "+------------------+-------+\n",
      "|               1.0|    425|\n",
      "|               1.0|     22|\n",
      "|               1.0|    431|\n",
      "|               1.0|    246|\n",
      "|               1.0|    187|\n",
      "|               1.0|    139|\n",
      "|               1.0|    269|\n",
      "|0.9416581659608296|    202|\n",
      "|0.9361048010849069|    245|\n",
      "|0.9141509546609883|    155|\n",
      "|0.9135757522099837|    157|\n",
      "| 0.912422554583911|    197|\n",
      "|0.9104215165809344|    416|\n",
      "|0.9104215165809344|    234|\n",
      "|0.9102134450999559|     71|\n",
      "|0.9031583971532898|    256|\n",
      "|0.8902769483214518|     82|\n",
      "|0.8894599278033617|     33|\n",
      "|0.8729578504863073|    237|\n",
      "|0.8722041236986973|    448|\n",
      "+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sorted desc\n",
    "new_df.orderBy(new_df.distance.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+--------------------+--------------------+\n",
      "|          distance|test_id|       description_x|       description_y|\n",
      "+------------------+-------+--------------------+--------------------+\n",
      "|               1.0|    425|vanguard extended...|vang ext mkt idx ins|\n",
      "|               1.0|     22|vanguard total bo...|vang tot bd mk is pl|\n",
      "|               1.0|    431|     fid sel biotech|fidelity select b...|\n",
      "|               1.0|    246|the growth fund o...|amer fds grwth fd...|\n",
      "|               1.0|    187| vang tot bd mkt adm|vanguard total bo...|\n",
      "|               1.0|    139|        coca cola co|   coca-cola company|\n",
      "|               1.0|    269|vanguard total bo...|vang tot bd mkt inst|\n",
      "|0.9416581659608296|    202|ishares core msci...|harding loevner e...|\n",
      "|0.9361048010849069|    245|vanguard short te...|vanguard short-te...|\n",
      "|0.9141509546609883|    155|vanguard total bo...|vang tot bd mk is pl|\n",
      "|0.9135757522099837|    157|vanguard mid-cap ...|vang midcap idx inst|\n",
      "| 0.912422554583911|    197|lazard emerging m...| lzrd emrg mkts eq o|\n",
      "|0.9104215165809344|    416| vang tot bd mkt adm|vanguard total bo...|\n",
      "|0.9104215165809344|    234| vang tot bd mkt adm|vanguard total bo...|\n",
      "|0.9102134450999559|     71|baidu inc spons a...|baidu inc - spon adr|\n",
      "|0.9031583971532898|    256|vanguard total bo...|vang tot bd mk is pl|\n",
      "|0.8902769483214518|     82|sptn inter treas ...| sptn int tr idx adv|\n",
      "|0.8894599278033617|     33|vanguard ltd-trm ...|vanguard limited-...|\n",
      "|0.8729578504863073|    237|blckrck inflation...|blackrock inflati...|\n",
      "|0.8722041236986973|    448|vanguard total bo...|vanguard ttl bnd ...|\n",
      "+------------------+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let't inspect manually\n",
    "df1 = new_df.alias('df1')\n",
    "df2 = q4_df.alias('df2')\n",
    "\n",
    "df1.join(df2, df1.test_id == df2.test_id).select([\"df1.*\",\"df2.description_x\",\"df2.description_y\"]).orderBy(df1.distance.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
